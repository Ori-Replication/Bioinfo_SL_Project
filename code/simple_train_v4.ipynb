{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "from time import time\n",
    "import os\n",
    "import torch_geometric.transforms as T\n",
    "from MyLoader import HeteroDataset\n",
    "from torch_geometric.loader import HGTLoader, NeighborLoader\n",
    "# from dataloader import DataLoaderMasking \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from model import HGT, HGT4Classification, HGT_ESM_4Classification, HGT_ESM_Attention_4Classification, HGT_ESM_CLdata_4Classification\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "import torch.nn.init as init\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score,auc,balanced_accuracy_score,cohen_kappa_score,precision_recall_curve, average_precision_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, EsmModel\n",
    "import joblib\n",
    "import torch_sparse\n",
    "from itertools import chain\n",
    "import datetime\n",
    "\n",
    "from utils import generate_log_dir,set_logger, compute_accuracy, Downstream_data_preprocess, override_config, GenePairDataset, sequence_dataset , create_optimizer,FocalLoss , override_config, load_esm_embedding_data, load_cell_line_gene_data\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args :\n",
    "    def __init__(self):\n",
    "        self.Full_data_path=r'../data/download_data/kgdata.pkl'\n",
    "        self.node_type='gene/protein'\n",
    "        self.Task_data_path = '../data/train_data/Cell_line_specific'\n",
    "        self.Save_model_path = '../logs_models/train_logs_models/'\n",
    "        self.processed_data_path = '../data/processed_data/'\n",
    "        self.init_checkpoint = '../logs_models/pretrained_models/Primekg_HGT_0.2_0.001'\n",
    "        self.cv = 'CV3'\n",
    "        self.do_low_data = False\n",
    "        self.sample_nodes = 1024\n",
    "        self.sample_layers = 4\n",
    "        self.num_workers = 8\n",
    "        self.specific = True # Cell line specific\n",
    "        self.adapted = True # Cell line adapted\n",
    "        self.cell_line_list = ['Jurkat']\n",
    "        self.test_cell_line = 'A549'\n",
    "        self.freeze_graph_encoder = True\n",
    "        self.freeze_esm_encoder = True\n",
    "        self.folds = 5\n",
    "        self.do_train = True\n",
    "        self.train_batch_size = 512\n",
    "        self.test_batch_size = 512\n",
    "        self.hgt_emb_dim = 128\n",
    "        self.hgt_num_heads = 4\n",
    "        self.hgt_dropout_ratio = 0.2\n",
    "        self.hgt_num_layer = 4\n",
    "        self.mlp_hidden_dim = 256\n",
    "        self.lr = 1e-5\n",
    "        self.device = 'cuda:2'\n",
    "        self.device_0 = 'cuda:0'\n",
    "        self.device_1 = 'cuda:1'\n",
    "        self.device_2 = 'cuda:2'\n",
    "        self.device_3 = 'cuda:3'\n",
    "        self.esm_sequence_max_length = 256\n",
    "        self.epoch = 20\n",
    "        self.use_esm_embedding = True\n",
    "        self.esm_embedding_file = '../data/download_data/gene_esm2emb.pkl'\n",
    "        self.decay = 1e-6\n",
    "        self.attention_classifier_num_heads = 4\n",
    "        self.weight_decay = 1e-5\n",
    "        self.esm_reduction_dim = 256\n",
    "        self.hgt_lr = 1e-5\n",
    "        self.fc_lr = 1e-4\n",
    "        self.fc_weight_decay = 1e-5\n",
    "        self.base_weight_decay = 0\n",
    "        self.use_layer_lr = False\n",
    "        self.loss_function = 'FocalLoss'\n",
    "        \n",
    "        \n",
    "args=args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = set_logger(args)\n",
    "logger = logging.getLogger('')  # 获取默认日志记录器\n",
    "with open (args.Full_data_path,'rb') as f:\n",
    "    kgdata=pickle.load(f)\n",
    "    \n",
    "logger.info(\"Loaded kgdata from {}\".format(args.Full_data_path))\n",
    "\n",
    "with open(\"../data/processed_data/gene_protein_2_id.json\",'rb') as f:\n",
    "    node_index=json.load(f)\n",
    "sequence_data = pd.read_csv('../data/train_data/uniprot_results_filtered.csv')\n",
    "sequence_data['Gene_id'] = sequence_data['Gene Name'].map(node_index['gene/protein'])\n",
    "if args.init_checkpoint:  \n",
    "    override_config(args)\n",
    "\n",
    "esm_embedding_geneid = load_esm_embedding_data(args, node_index)\n",
    "logger.info(\"Loaded ESM embeddings from {}\".format(args.esm_embedding_file))\n",
    "\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "\n",
    "gene_protein=node_index[args.node_type] \n",
    "eval_metric_folds={'fold':[],'auc':[],'aupr':[],'f1':[],'bacc':[],'kappa':[]}\n",
    "node_type=args.node_type\n",
    "num_nodes_type=len(kgdata.node_types)\n",
    "num_edge_type=len(kgdata.edge_types)\n",
    "num_nodes=kgdata.num_nodes\n",
    "input_node_embeddings = torch.nn.Embedding(num_nodes_type, 16)\n",
    "torch.nn.init.xavier_uniform_(input_node_embeddings.weight.data)\n",
    "for i in range(len(kgdata.node_types)):\n",
    "    num_repeat=kgdata[kgdata.node_types[i]].x.shape[0]\n",
    "    kgdata[kgdata.node_types[i]].x =input_node_embeddings(torch.tensor(i)).repeat([num_repeat,1]).detach()\n",
    "\n",
    "\n",
    "\n",
    "eval_metric_folds = {'fold':[], 'auc':[], 'aupr':[], 'f1':[], 'bacc':[], 'kappa':[]}\n",
    "\n",
    "if args.loss_function == 'FocalLoss':\n",
    "    criterion = FocalLoss(alpha = 0.9, gamma = 2.0, reduction = 'mean') \n",
    "    logging.info(\"Using criterion FocalLoss, alpha = 0.9, gamma = 2.0\")\n",
    "elif args.loss_function == 'CrossEntropyLoss':\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "\n",
    "\n",
    "logging.info(f\"Cell line specific\")\n",
    "for cell_line in args.cell_line_list:\n",
    "    \n",
    "    cell_line_log_dir = os.path.join(log_dir, cell_line)\n",
    "    if not os.path.exists(cell_line_log_dir):\n",
    "        os.makedirs(cell_line_log_dir)\n",
    "    cell_line_gene_data = load_cell_line_gene_data(args, cell_line) \n",
    "    cell_line_gene_data['Gene_id'] = cell_line_gene_data['Gene Name'].map(node_index['gene/protein'])   \n",
    "    logger.info(f\"Loaded {cell_line} gene data from {args.Task_data_path}\")\n",
    "    \n",
    "    for fold in range(args.folds):\n",
    "\n",
    "        fold_log_dir = os.path.join(cell_line_log_dir, f'fold_{fold}')\n",
    "        if not os.path.exists(fold_log_dir):\n",
    "            os.makedirs(fold_log_dir)\n",
    "        best_auc = 0\n",
    "        \n",
    "        HGT_model = HGT(kgdata,2*args.hgt_emb_dim,args.hgt_emb_dim,args.hgt_num_heads,args.hgt_num_layer).to(args.device)\n",
    "\n",
    "        if args.init_checkpoint: \n",
    "            # Restore model from checkpoint directory  \n",
    "            logging.info('Loading checkpoint %s...' % args.init_checkpoint)\n",
    "            checkpoint = torch.load(os.path.join(args.init_checkpoint, 'checkpoint'))\n",
    "            init_step = checkpoint['step']\n",
    "            HGT_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            \n",
    "        HGT_ESM_CLdata_4Classification_model = HGT_ESM_CLdata_4Classification(args, HGT_model).to(args.device)\n",
    "        logging.info(f\"Using HGT_ESM_CLdata_4Classification_model\")\n",
    "        \n",
    "        \n",
    "        if args.use_layer_lr:\n",
    "            optimizer_model = create_optimizer(HGT_ESM_CLdata_4Classification_model,args.hgt_lr, args.fc_lr, args.base_weight_decay, args.fc_weight_decay)\n",
    "        else:\n",
    "            optimizer_model = optim.Adam(HGT_ESM_CLdata_4Classification_model.parameters(), lr=args.hgt_lr, weight_decay=args.fc_weight_decay)\n",
    "        \n",
    "        train_data,test_data,train_mask,test_mask,num_train_node,num_test_node=Downstream_data_preprocess(args,fold,gene_protein,cell_line)\n",
    "        best_metrics = {'auc': 0, 'aupr': 0, 'f1': 0, 'bacc': 0, 'kappa': 0}\n",
    "        loss_sum = 0\n",
    "        edge_used=[]\n",
    "            # map gene name(column name) to gene id\n",
    "        training_logs = []\n",
    "        testing_logs=[]\n",
    "        prediction_result_log_fold=[]\n",
    "        label_log_fold = []\n",
    "    \n",
    "        auc_sum_fold=[]\n",
    "        aupr_sum_fold=[]\n",
    "        f1_sum_fold=[]\n",
    "        bacc_sum_fold=[]\n",
    "        kappa_sum_fold=[]\n",
    "        \n",
    "        best_model_path = os.path.join(log_dir, 'best_model.pth')\n",
    "        \n",
    "        logger.info(f\"Training {cell_line} fold {fold}\")\n",
    "        \n",
    "        for epoch in tqdm(range(args.epoch)):\n",
    "            HGT_ESM_CLdata_4Classification_model.train()\n",
    "            gene_pair_loader = DataLoader(GenePairDataset(train_data), batch_size=args.train_batch_size, shuffle=True)\n",
    "            # Train\n",
    "            prediction_result_log_epoch=[]\n",
    "            label_log_epoch = []\n",
    "            loss_sum = 0\n",
    "            for step,batch in enumerate(tqdm(gene_pair_loader)):\n",
    "                optimizer_model.zero_grad()\n",
    "                node_a = batch[:, 0]\n",
    "                node_b = batch[:, 1]\n",
    "                node = torch.cat([node_a, node_b], dim=0)\n",
    "                label = batch[:, 2].to(args.device)\n",
    "                node_set = set(node_a.numpy()) | set(node_b.numpy())\n",
    "                unique_node = list(node_set)\n",
    "                len_unique_node = len(unique_node)\n",
    "                node_mask = torch.zeros((27671)) # The number of gene/protein nodes in kg\n",
    "                node_mask[unique_node] = 1\n",
    "                node_mask = node_mask.bool()\n",
    "                \n",
    "                kg_loader = HGTLoader(kgdata,\n",
    "                    num_samples={key: [args.sample_nodes] * args.sample_layers for key in kgdata.node_types},\n",
    "                    shuffle=False,\n",
    "                    batch_size=len_unique_node,\n",
    "                    input_nodes=(node_type,node_mask),\n",
    "                    num_workers=args.num_workers) \n",
    "                for kg_batch in kg_loader:\n",
    "                    break\n",
    "                kg_batch.to(args.device)\n",
    "                ESM_nodea_emb = torch.stack([esm_embedding_geneid[one_node.item()] for one_node in node_a]).to(args.device)\n",
    "                ESM_nodeb_emb = torch.stack([esm_embedding_geneid[one_node.item()] for one_node in node_b]).to(args.device)\n",
    "                \n",
    "                cell_line_gene_data_nodea = []\n",
    "                for one_node in node_a:\n",
    "                    selected_data = cell_line_gene_data.loc[cell_line_gene_data['Gene_id'] == one_node.item(), ['CN', 'Expression', 'HotspotMutation']]\n",
    "                    cell_line_gene_data_nodea.append(selected_data.values.tolist())\n",
    "                cell_line_gene_data_nodea_embedding = torch.tensor(np.array(cell_line_gene_data_nodea).squeeze())\n",
    "                cell_line_gene_data_nodeb = []\n",
    "                for one_node in node_b:\n",
    "                    selected_data = cell_line_gene_data.loc[cell_line_gene_data['Gene_id'] == one_node.item(), ['CN', 'Expression', 'HotspotMutation']]\n",
    "                    cell_line_gene_data_nodeb.append(selected_data.values.tolist())\n",
    "                cell_line_gene_data_nodeb_embedding = torch.tensor(np.array(cell_line_gene_data_nodeb).squeeze())\n",
    "                \n",
    "                cell_line_gene_data_nodea_embedding = cell_line_gene_data_nodea_embedding.float().to(args.device)\n",
    "                cell_line_gene_data_nodeb_embedding = cell_line_gene_data_nodeb_embedding.float().to(args.device)\n",
    "                \n",
    "                prediction_result = HGT_ESM_CLdata_4Classification_model(args.node_type, args.train_batch_size , kg_batch,batch,ESM_nodea_emb,ESM_nodeb_emb, cell_line_gene_data_nodea_embedding, cell_line_gene_data_nodeb_embedding)\n",
    "                \n",
    "\n",
    "\n",
    "                label = label.long()\n",
    "                loss = criterion(prediction_result, label)\n",
    "                loss.backward()\n",
    "                loss_sum += loss.item()\n",
    "                torch.nn.utils.clip_grad_norm_(HGT_ESM_CLdata_4Classification_model.parameters(), max_norm=1.0)\n",
    "                optimizer_model.step()\n",
    "            \n",
    "            # valid\n",
    "            HGT_ESM_CLdata_4Classification_model.eval()\n",
    "            gene_pair_loader = DataLoader(GenePairDataset(test_data), batch_size=args.test_batch_size, shuffle=False)\n",
    "            edge_used=[]\n",
    "            with torch.no_grad():\n",
    "                for step,batch in enumerate(tqdm(gene_pair_loader)):\n",
    "                    node_a = batch[:, 0]\n",
    "                    node_b = batch[:, 1]\n",
    "                    node = torch.cat([node_a, node_b], dim=0)\n",
    "                    label = batch[:, 2].to(args.device)\n",
    "                    node_set = set(node_a.numpy()) | set(node_b.numpy())\n",
    "                    unique_node = list(node_set)\n",
    "                    len_unique_node = len(unique_node)\n",
    "                    node_mask = torch.zeros((27671))\n",
    "                    node_mask[unique_node] = 1\n",
    "                    node_mask = node_mask.bool()\n",
    "                    \n",
    "                    kg_loader = HGTLoader(kgdata,\n",
    "                        num_samples={key: [args.sample_nodes] * args.sample_layers for key in kgdata.node_types},\n",
    "                        shuffle=False,\n",
    "                        batch_size=len_unique_node,\n",
    "                        input_nodes=(node_type,node_mask),\n",
    "                        num_workers=args.num_workers)\n",
    "                    \n",
    "                    for kg_batch in kg_loader:\n",
    "                        break\n",
    "                    kg_batch.to(args.device)\n",
    "                    \n",
    "                    ESM_nodea_emb = torch.stack([esm_embedding_geneid[one_node.item()] for one_node in node_a]).to(args.device)\n",
    "                    ESM_nodeb_emb = torch.stack([esm_embedding_geneid[one_node.item()] for one_node in node_b]).to(args.device)\n",
    "                    \n",
    "                    cell_line_gene_data_nodea = []\n",
    "                    for one_node in node_a:\n",
    "                        selected_data = cell_line_gene_data.loc[cell_line_gene_data['Gene_id'] == one_node.item(), ['CN', 'Expression', 'HotspotMutation']]\n",
    "                        cell_line_gene_data_nodea.append(selected_data.values.tolist())\n",
    "                    cell_line_gene_data_nodea_embedding = torch.tensor(np.array(cell_line_gene_data_nodea).squeeze())\n",
    "                    cell_line_gene_data_nodeb = []\n",
    "                    for one_node in node_b:\n",
    "                        selected_data = cell_line_gene_data.loc[cell_line_gene_data['Gene_id'] == one_node.item(), ['CN', 'Expression', 'HotspotMutation']]\n",
    "                        cell_line_gene_data_nodeb.append(selected_data.values.tolist())\n",
    "                    cell_line_gene_data_nodeb_embedding = torch.tensor(np.array(cell_line_gene_data_nodeb).squeeze())\n",
    "                    \n",
    "                    cell_line_gene_data_nodea_embedding = cell_line_gene_data_nodea_embedding.float().to(args.device)\n",
    "                    cell_line_gene_data_nodeb_embedding = cell_line_gene_data_nodeb_embedding.float().to(args.device)\n",
    "                    \n",
    "                    prediction_result = HGT_ESM_CLdata_4Classification_model(args.node_type, args.train_batch_size , kg_batch,batch,ESM_nodea_emb,ESM_nodeb_emb, cell_line_gene_data_nodea_embedding, cell_line_gene_data_nodeb_embedding)\n",
    "                    prediction_result_log_epoch.append(prediction_result.detach().cpu().numpy())\n",
    "                    label_log_epoch.append(label.tolist())\n",
    "            prediction_result_log_epoch = np.concatenate(prediction_result_log_epoch)\n",
    "            label_log_epoch_flat = np.array(list(chain.from_iterable(label_log_epoch)))\n",
    "            \n",
    "\n",
    "\n",
    "            aucu, aupr, f1, kappa, bacc = compute_accuracy(label_log_epoch_flat, np.array(prediction_result_log_epoch).argmax(axis=1), prediction_result_log_epoch)\n",
    "            auc_sum_fold.append(aucu)\n",
    "            aupr_sum_fold.append(aupr)\n",
    "            f1_sum_fold.append(f1)\n",
    "            bacc_sum_fold.append(bacc)\n",
    "            kappa_sum_fold.append(kappa)\n",
    "            if aucu > best_metrics['auc']:\n",
    "                best_metrics = {'auc': aucu, 'aupr': aupr, 'f1': f1, 'bacc': bacc, 'kappa': kappa}\n",
    "                best_model_path = os.path.join(fold_log_dir, 'best_model.pth')\n",
    "                torch.save(HGT_ESM_CLdata_4Classification_model.state_dict(), best_model_path)\n",
    "            logger.info(f\"Epoch {epoch}, Loss: {loss_sum}, AUC: {aucu}, AUPR: {aupr}, F1: {f1}, Kappa: {kappa}, BAcc: {bacc}\")\n",
    "            \n",
    "        eval_metric_folds['fold'].append(fold)\n",
    "        eval_metric_folds['auc'].append(best_metrics['auc'])\n",
    "        eval_metric_folds['aupr'].append(best_metrics['aupr'])\n",
    "        eval_metric_folds['f1'].append(best_metrics['f1'])\n",
    "        eval_metric_folds['bacc'].append(best_metrics['bacc'])\n",
    "        eval_metric_folds['kappa'].append(best_metrics['kappa'])\n",
    "        \n",
    "        \n",
    "    avg_metrics = {key: np.mean(values) for key, values in eval_metric_folds.items() if key != 'fold'}\n",
    "    # cell line\n",
    "    logger.info(f\"{cell_line} Average Metrics:{avg_metrics}\")\n",
    "    best_metrics = {key: max(values) for key, values in eval_metric_folds.items() if key != 'fold'}\n",
    "    logger.info(f\"{cell_line} Best Metrics: {best_metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinfo_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
