{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/original_data/Cell_line_specific/A375.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m A549_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/original_data/Cell_line_specific/A549.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m Jurkat_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/original_data/Cell_line_specific/Jurkat.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m A375_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA375_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m A549_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(A549_path)\n\u001b[1;32m      9\u001b[0m Jurkat_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(Jurkat_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/bioinfo/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bioinfo/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/bioinfo/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bioinfo/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/bioinfo/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/original_data/Cell_line_specific/A375.csv'"
=======
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [0,1,2,3,4]\n",
    "\n",
    "A375_path = \"../data/original_data/A375.csv\"\n",
    "A549_path = \"../data/original_data/A549.csv\"\n",
    "Jurkat_path = \"../data/original_data/Jurkat.csv\"\n",
    "\n",
    "\n",
    "\n",
    "A375_df = pd.read_csv(A375_path)\n",
    "A549_df = pd.read_csv(A549_path)\n",
    "Jurkat_df = pd.read_csv(Jurkat_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene1_name</th>\n",
       "      <th>gene2_name</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAP2K2</td>\n",
       "      <td>UBC</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HSP90AA1</td>\n",
       "      <td>MAP2K2</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEK2</td>\n",
       "      <td>MAP2K2</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AKT1</td>\n",
       "      <td>MAP2K2</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCL2</td>\n",
       "      <td>MAP2K2</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>MAPK3</td>\n",
       "      <td>WEE1</td>\n",
       "      <td>A375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>BRCA2</td>\n",
       "      <td>MAPK3</td>\n",
       "      <td>A375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>MAPK3</td>\n",
       "      <td>MCL1</td>\n",
       "      <td>A375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>HSP90AA1</td>\n",
       "      <td>WEE1</td>\n",
       "      <td>A375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>HSP90AA1</td>\n",
       "      <td>MTOR</td>\n",
       "      <td>A375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gene1_name gene2_name cell_line  label\n",
       "0       MAP2K2        UBC      A375      0\n",
       "1     HSP90AA1     MAP2K2      A375      0\n",
       "2        CHEK2     MAP2K2      A375      0\n",
       "3         AKT1     MAP2K2      A375      0\n",
       "4         BCL2     MAP2K2      A375      0\n",
       "..         ...        ...       ...    ...\n",
       "530      MAPK3       WEE1      A375      1\n",
       "531      BRCA2      MAPK3      A375      1\n",
       "532      MAPK3       MCL1      A375      1\n",
       "533   HSP90AA1       WEE1      A375      1\n",
       "534   HSP90AA1       MTOR      A375      1\n",
       "\n",
       "[535 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A375_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gene1_name gene2_name cell_line  label\n",
      "66       BRCA2      MAPK3      A375      0\n",
      "129   HSP90AA1       WEE1      A375      0\n",
      "130   HSP90AA1      PARP1      A375      0\n",
      "133   HSP90AA1       MTOR      A375      0\n",
      "144     BCL2L1      PARP1      A375      0\n",
      "145       MTOR      PARP1      A375      0\n",
      "146       MCL1      PARP1      A375      0\n",
      "156     BCL2L1       MCL1      A375      0\n",
      "157      MAPK3       MCL1      A375      0\n",
      "179      MAPK3       WEE1      A375      0\n",
      "180     BCL2L1      MAPK3      A375      0\n",
      "216     BCL2L1       WEE1      A375      0\n",
      "270      BRCA1      PARP1      A375      0\n",
      "273      BRCA2      PARP1      A375      0\n",
      "521     BCL2L1       MCL1      A375      1\n",
      "522   HSP90AA1      PARP1      A375      1\n",
      "523     BCL2L1      MAPK3      A375      1\n",
      "524       MCL1      PARP1      A375      1\n",
      "525      BRCA2      PARP1      A375      1\n",
      "526      BRCA1      PARP1      A375      1\n",
      "527     BCL2L1       WEE1      A375      1\n",
      "528     BCL2L1      PARP1      A375      1\n",
      "529       MTOR      PARP1      A375      1\n",
      "530      MAPK3       WEE1      A375      1\n",
      "531      BRCA2      MAPK3      A375      1\n",
      "532      MAPK3       MCL1      A375      1\n",
      "533   HSP90AA1       WEE1      A375      1\n",
      "534   HSP90AA1       MTOR      A375      1\n",
      "28\n"
>>>>>>> 8bca95abc1c4f175628ead7cac167a185f8ce3ec
     ]
    }
   ],
   "source": [
    "# 找到重复的行\n",
    "duplicates = A375_df[A375_df.duplicated(subset=['gene1_name', 'gene2_name'], keep=False)]\n",
    "\n",
    "# 显示结果\n",
    "print(duplicates)\n",
    "print(len(duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df):\n",
    "    # 根据 gene1_name 和 gene2_name 进行分组\n",
    "    grouped = df.groupby(['gene1_name', 'gene2_name'])\n",
    "    \n",
    "    # 用于存储过滤后的行的列表\n",
    "    filtered_rows = []\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        # 检查组内是否存在 label 为 1 的行\n",
    "        has_label_1 = any(group['label'] == 1)\n",
    "        \n",
    "        if has_label_1:\n",
    "            # 将 label 为 0 的行过滤掉，保留 label 为 1 的行\n",
    "            filtered_group = group[group['label'] == 1]\n",
    "        else:\n",
    "            # 如果组内没有 label 为 1 的行，则保留一个 label 为 0 的行\n",
    "            filtered_group = group[group['label'] == 0].head(1)\n",
    "        \n",
    "        # 将过滤后的行添加到结果列表中\n",
    "        filtered_rows.append(filtered_group)\n",
    "    \n",
    "    # 将过滤后的行合并成一个 DataFrame\n",
    "    filtered_df = pd.concat(filtered_rows)\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "A375_filtered = filter_df(A375_df)\n",
    "A549_filtered = filter_df(A549_df)\n",
    "Jurkat_filtered = filter_df(Jurkat_df)"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "save_path = \"../data/train_data\"\n",
    "\n",
    "A375_filtered.to_csv(f\"{save_path}/A375_filtered.csv\", index=False)\n",
    "A549_filtered.to_csv(f\"{save_path}/A549_filtered.csv\", index=False)\n",
    "Jurkat_filtered.to_csv(f\"{save_path}/Jurkat_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and valid\n",
    "# 5 fold\n",
    "def split_train_valid(df, n_folds=5):\n",
    "    # 将数据集按照 gene1_name 和 gene2_name 进行分组\n",
    "    grouped = df.groupby(['gene1_name', 'gene2_name'])\n",
    "    \n",
    "    # 用于存储划分结果的列表\n",
    "    splits = []\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        # 将组内的数据按照 gene1_name 和 gene2_name 进行分组后，随机划分为 n_folds 份\n",
    "        group_splits = np.random.randint(0, n_folds, size=len(group))\n",
    "        \n",
    "        # 将划分结果添加到结果列表中\n",
    "        splits.append(group_splits)\n",
    "    \n",
    "    # 将划分结果合并成一个 Series\n",
    "    splits = pd.Series(np.concatenate(splits), index=df.index)\n",
    "    \n",
    "    return splits\n",
    "\n",
    "for fold in folds:\n",
    "    A375_splits = split_train_valid(A375_filtered)\n",
    "    A549_splits = split_train_valid(A549_filtered)\n",
    "    Jurkat_splits = split_train_valid(Jurkat_filtered)\n",
    "    \n",
    "    A375_filtered['split'] = A375_splits\n",
    "    A549_filtered['split'] = A549_splits\n",
    "    Jurkat_filtered['split'] = Jurkat_splits\n",
    "    \n",
    "    A375_train = A375_filtered[A375_filtered['split'] != fold]\n",
    "    A375_train = A375_train.drop(columns=['split'])\n",
    "    A375_valid = A375_filtered[A375_filtered['split'] == fold]\n",
    "    A375_valid = A375_valid.drop(columns=['split'])\n",
    "    \n",
    "    A549_train = A549_filtered[A549_filtered['split'] != fold]\n",
    "    A549_train = A549_train.drop(columns=['split'])\n",
    "    A549_valid = A549_filtered[A549_filtered['split'] == fold]\n",
    "    A549_valid = A549_valid.drop(columns=['split'])\n",
    "    \n",
    "    Jurkat_train = Jurkat_filtered[Jurkat_filtered['split'] != fold]\n",
    "    Jurkat_train = Jurkat_train.drop(columns=['split'])\n",
    "    Jurkat_valid = Jurkat_filtered[Jurkat_filtered['split'] == fold]\n",
    "    Jurkat_valid = Jurkat_valid.drop(columns=['split'])\n",
    "    \n",
    "    A375_train.to_csv(f\"{save_path}/Cell_line_specific/A375/train_{fold}.csv\", index=False)\n",
    "    A375_valid.to_csv(f\"{save_path}/Cell_line_specific/A375/valid_{fold}.csv\", index=False)\n",
    "    \n",
    "    A549_train.to_csv(f\"{save_path}/Cell_line_specific/A549/train_{fold}.csv\", index=False)\n",
    "    A549_valid.to_csv(f\"{save_path}/Cell_line_specific/A549/valid_{fold}.csv\", index=False)\n",
    "    \n",
    "    Jurkat_train.to_csv(f\"{save_path}/Cell_line_specific/Jurkat/train_{fold}.csv\", index=False)\n",
    "    Jurkat_valid.to_csv(f\"{save_path}/Cell_line_specific/Jurkat/valid_{fold}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 8bca95abc1c4f175628ead7cac167a185f8ce3ec
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
