{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "from time import time\n",
    "import os\n",
    "import torch_geometric.transforms as T\n",
    "from MyLoader import HeteroDataset\n",
    "from torch_geometric.loader import HGTLoader, NeighborLoader\n",
    "# from dataloader import DataLoaderMasking \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from model import HGT\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "import torch.nn.init as init\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score,auc,balanced_accuracy_score,cohen_kappa_score,precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args :\n",
    "    def __init__(self):\n",
    "        self.Full_data_path=r'../data/download_data/kgdata.pkl'\n",
    "        self.node_type='gene/protein'\n",
    "        self.Task_data_path = '../data/original_data/Cell_line_specific'\n",
    "        self.cv = 'CV3'\n",
    "        self.n_fold = 5\n",
    "        self.device = 'cuda'\n",
    "        self.do_low_data = False\n",
    "        self.sample_nodes = 1024\n",
    "        self.sample_layers = 4\n",
    "        self.num_workers = 8\n",
    "        self.specific = True # Cell line specific\n",
    "        self.adapted = True # Cell line adapted\n",
    "        self.cell_line_list = ['A375','Jurkat','A549']\n",
    "        self.test_cell_line = 'A549'\n",
    "        self.freeze_graph_encoder = True\n",
    "        self.freeze_esm_encoder = True\n",
    "        self.folds = 5\n",
    "        self.do_train = True\n",
    "        \n",
    "args=args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_logger(args):\n",
    "    '''\n",
    "    Write logs to checkpoint and console \n",
    "    '''\n",
    "\n",
    "    if args.do_train:\n",
    "        # train_log=str(linear_layer_count)+'_'+args.lr+'_'+'train.log'\n",
    "        log_file = os.path.join(args.Save_model_path or args.init_checkpoint, 'train.log') \n",
    "    else:\n",
    "        log_file = os.path.join(args.Save_model_path or args.init_checkpoint, 'test.log') \n",
    "    \n",
    "    logging.basicConfig(\n",
    "        format='%(asctime)s %(levelname)-8s %(message)s', \n",
    "        level=logging.INFO,  # \n",
    "        datefmt='%Y-%m-%d %H:%M:%S', \n",
    "        filename=log_file, \n",
    "        filemode='w'  \n",
    "    )\n",
    "    console = logging.StreamHandler() # \n",
    "    console.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(message)s') \n",
    "    console.setFormatter(formatter) \n",
    "    logging.getLogger('').addHandler(console) \n",
    "    \n",
    "def compute_accuracy(target,pred, pred_edge):\n",
    "    \n",
    "    target=target.clone().detach().cpu().numpy()\n",
    "    pred=pred.clone().detach().cpu().numpy()\n",
    "    pred_edge=pred_edge.clone().detach().cpu()\n",
    "    scores = torch.softmax(pred_edge, 1).numpy()\n",
    "    target=target.astype(int)\n",
    "   \n",
    "    aucu=roc_auc_score(target,scores[:,1])\n",
    "    precision_tmp, recall_tmp, _thresholds = precision_recall_curve(target, pred)\n",
    "    aupr = auc(recall_tmp, precision_tmp)\n",
    "    f1 = f1_score(target,pred)\n",
    "    kappa=cohen_kappa_score(target,pred)\n",
    "    bacc=balanced_accuracy_score(target,pred)\n",
    "    \n",
    "    return aucu,aupr,f1,kappa,bacc\n",
    "def Downstream_data_preprocess(args,n_fold,node_type_dict,cell_line): #FIXME\n",
    "    \"\"\"\n",
    "    load SL data and preprocess before training \n",
    "    \"\"\"\n",
    "    task_data_path=args.Task_data_path\n",
    "    train_data=pd.read_csv(f\"{task_data_path}/{cell_line}/sl_train_{n_fold}.csv\")\n",
    "    test_data=pd.read_csv(f\"{task_data_path}/{cell_line}/sl_test_{n_fold}.csv\",)\n",
    "    train_data.columns=[0,1,2,3]\n",
    "    test_data.columns=[0,1,2,3]\n",
    "    train_data[0]=train_data[0].astype(str).map(node_type_dict)\n",
    "    train_data[1]=train_data[1].astype(str).map(node_type_dict)\n",
    "    test_data[0]=test_data[0].astype(str).map(node_type_dict)\n",
    "    test_data[1]=test_data[1].astype(str).map(node_type_dict)\n",
    "    train_data=train_data.dropna()\n",
    "    test_data=test_data.dropna()\n",
    "    train_data[0]=train_data[0].astype(int)\n",
    "    train_data[1]=train_data[1].astype(int)\n",
    "    test_data[0]=test_data[0].astype(int)\n",
    "    test_data[1]=test_data[1].astype(int)\n",
    "    # low data scenario settings\n",
    "    if args.do_low_data:\n",
    "        num_sample=int(train_data.shape[0]*args.train_data_ratio)\n",
    "        print(num_sample)\n",
    "        train_data=train_data.sample(num_sample,replace=False,random_state=0)\n",
    "        train_data.reset_index(inplace=True)\n",
    "        print(f'train_data.size:{train_data.shape[0]}')\n",
    "\n",
    "    train_node=list(set(train_data[0])|set(train_data[1]))\n",
    "    print(f'train_node.size:{len(train_node)}')\n",
    "    train_mask=torch.zeros((27671))\n",
    "    test_mask=torch.zeros((27671))\n",
    "    test_node=list(set(test_data[0])|set(test_data[1]))\n",
    "    train_mask[train_node]=1\n",
    "    test_mask[test_node]=1\n",
    "    train_mask=train_mask.bool()\n",
    "    test_mask=test_mask.bool()\n",
    "    num_train_node=len(train_node)\n",
    "    num_test_node=len(test_node)\n",
    "    return train_data,test_data,train_mask,test_mask,num_train_node,num_test_node\n",
    "\n",
    "def Construct_loader(args,kgdata,train_mask,test_mask,node_type,num_train_node,num_test_node):\n",
    "    \"\"\"\n",
    "    construct loader for train/test data\n",
    "    \"\"\"\n",
    "\n",
    "    train_loader = HGTLoader(kgdata,\n",
    "    num_samples={key: [args.sample_nodes] * args.sample_layers for key in kgdata.node_types},shuffle=False,\n",
    "    batch_size=num_train_node,\n",
    "    input_nodes=(node_type,train_mask),num_workers=args.num_workers)\n",
    "\n",
    "    test_loader=HGTLoader(kgdata,\n",
    "    num_samples={key: [args.sample_nodes] * args.sample_layers for key in kgdata.node_types},\n",
    "    batch_size=num_test_node,\n",
    "    input_nodes=(node_type,test_mask),num_workers=args.num_workers,shuffle=False)\n",
    "\n",
    "    return train_loader,test_loader\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph_embedding_dim = 128,\n",
    "        transformer_depth = 3,\n",
    "        num_transformer_heads = 4,\n",
    "        num_classes = 2,\n",
    "        graph_encoder = HGT,\n",
    "        ):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "set_logger(args)\n",
    "with open (args.Full_data_path,'rb') as f:\n",
    "    kgdata=pickle.load(f)\n",
    "with open(\"../data/processed_data/gene_protein_2_id.json\",'rb') as f:\n",
    "    node_index=json.load(f)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = torch.device(args.device)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "gene_protein=node_index[args.node_type] \n",
    "eval_metric_folds={'fold':[],'auc':[],'aupr':[],'f1':[],'bacc':[],'kappa':[]}\n",
    "node_type=args.node_type\n",
    "num_nodes_type=len(kgdata.node_types)\n",
    "num_edge_type=len(kgdata.edge_types)\n",
    "num_nodes=kgdata.num_nodes\n",
    "input_node_embeddings = torch.nn.Embedding(num_nodes_type, 16)\n",
    "torch.nn.init.xavier_uniform_(input_node_embeddings.weight.data)\n",
    "for i in range(len(kgdata.node_types)):\n",
    "    num_repeat=kgdata[kgdata.node_types[i]].x.shape[0]\n",
    "    kgdata[kgdata.node_types[i]].x =input_node_embeddings(torch.tensor(i)).repeat([num_repeat,1]).detach()\n",
    "\n",
    "if args.specific:# Do cv within cell line\n",
    "    logging.info(f\"Cell line specific\")\n",
    "    for i in range(args.folds):\n",
    "        n_fold = i\n",
    "        train_data,test_data,train_mask,test_mask,num_train_node,num_test_node=Downstream_data_preprocess(args,args.cv,n_fold,gene_protein)\n",
    "        train_loader,test_loader=Construct_loader(args,kgdata,train_mask,test_mask,node_type,num_train_node,num_test_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27482</td>\n",
       "      <td>14366</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1592</td>\n",
       "      <td>16112</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13513</td>\n",
       "      <td>15543</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15020</td>\n",
       "      <td>25816</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27431</td>\n",
       "      <td>2881</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>16390</td>\n",
       "      <td>26768</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>19399</td>\n",
       "      <td>14930</td>\n",
       "      <td>A375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>26053</td>\n",
       "      <td>26913</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>7635</td>\n",
       "      <td>1035</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>9180</td>\n",
       "      <td>14299</td>\n",
       "      <td>A375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1     2  3\n",
       "0    27482  14366  A375  0\n",
       "1     1592  16112  A375  0\n",
       "2    13513  15543  A375  0\n",
       "3    15020  25816  A375  0\n",
       "4    27431   2881  A375  0\n",
       "..     ...    ...   ... ..\n",
       "423  16390  26768  A375  0\n",
       "424  19399  14930  A375  1\n",
       "425  26053  26913  A375  0\n",
       "426   7635   1035  A375  0\n",
       "427   9180  14299  A375  0\n",
       "\n",
       "[428 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metagpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
